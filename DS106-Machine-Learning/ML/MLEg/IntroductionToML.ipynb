{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7d7871",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "# First, you will need to import some packages. \n",
    "# You will need pandas for loading in data, numpy for square-rooting your model estimates, \n",
    "# sklearn for the bulk of the linear regression and modeling work, \n",
    "# and matplotlib to graph the model's residuals to get a visual representation of accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe460c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd00f6",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922f6a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.917</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012.917</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013.583</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013.500</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2012.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  X1 transaction date  X2 house age  \\\n",
       "0   1             2012.917          32.0   \n",
       "1   2             2012.917          19.5   \n",
       "2   3             2013.583          13.3   \n",
       "3   4             2013.500          13.3   \n",
       "4   5             2012.833           5.0   \n",
       "\n",
       "   X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
       "0                                84.87882                               10   \n",
       "1                               306.59470                                9   \n",
       "2                               561.98450                                5   \n",
       "3                               561.98450                                5   \n",
       "4                               390.56840                                5   \n",
       "\n",
       "   X5 latitude  X6 longitude  Y house price of unit area  \n",
       "0     24.98298     121.54024                        37.9  \n",
       "1     24.98034     121.53951                        42.2  \n",
       "2     24.98746     121.54391                        47.3  \n",
       "3     24.98746     121.54391                        54.8  \n",
       "4     24.97937     121.54245                        43.1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realestate = pd.read_csv(\"/Users/nehag/Documents/GitHub/DS-Student-Resources/DS106-Machine-Learning/ML/MLEg/realestate.csv\")\n",
    "realestate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ce165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal\n",
    "\n",
    "# With the above data, your goal is to accurately predict housing prices.\n",
    "# This variable is conveniently labeled Y house price of unit area for you.\n",
    "# You will use X variables numbered 2-6 to determine housing prices. When completed, if desired, \n",
    "# you should be able to take completely new data, maybe from a new geographic location, \n",
    "# and predict housing prices there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "\n",
    "# The first thing you need to do to kick off machine learning is to create \n",
    "# your x and y variables as their own arrays. You cannot feed in the entire dataframe all at once, \n",
    "# so you will need to subset your data. The x data will consist of X2-X6.\n",
    "# You are going to skip X1 since it is a date, and dates can sometimes be tricky to format correctly\n",
    "# for machine learning.\n",
    "\n",
    "x = realestate[['X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']]\n",
    "\n",
    "# The y data will consist of the target variable, or what you are trying to predict. In this case, that is \n",
    "# housing price:\n",
    "\n",
    "y =  realestate['Y house price of unit area']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e92186",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the key things that separates machine learning from statistics is that machine learning\n",
    "#utilizes the concept of \"train test split.\" In statistics, you typically run your analysis on all the data \n",
    "#you have available. In machine learning, you split your data in half, and reserve the first chunk for training \n",
    "#the model, and the second half for testing the model. How big should a \"chunk\" be? Typically you want more\n",
    "#data to be used for training than for testing. 80/20, 70/30, and 60/40 splits are all acceptable.\n",
    "\n",
    "#You will utilize the train_test_split() function from sklearn to split your data. You will end up with four \n",
    "#data sets at the end:\n",
    "\n",
    "#x_train\n",
    "#x_test\n",
    "#y_train\n",
    "#y_test\n",
    "#There will be one training dataset and one testing dataset each for x and y.\n",
    "\n",
    "#As arguments into the train_test_split() function, you will place your x and y data, and specify how much of \n",
    "#your data you want to test with the argument test_size=. In this case, the value of test_size= is .4, because \n",
    "#you are going to use a 60/40 train/test split. This means that you are reserving 40% of your data for testing,\n",
    "#and training with the remaining 60%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6a8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .4, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will note that another argument is included: random_state=101. This argument is not required when you \n",
    "# are doing machine learning on your own, but by everyone using the same number (101), \n",
    "# this means that your randomly generated 60% training data will be the same as what is seen in the lesson. \n",
    "# So, including the random_state= argument into the function makes it a bit easier to follow along, \n",
    "# because you will get the same results as what is presented here.\n",
    "\n",
    "# Once you have completed that line, if you want to see the shape of the data you'll be using for your\n",
    "# machine learning algorithm, you can then print it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9045d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248, 5) (248,)\n",
      "(166, 5) (166,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# This is showing that in the x_train dataset, there are 248 rows and 5 columns, and in the x_test dataset, \n",
    "# there are 166 rows and 5 columns. So you can see how the training and testing data is broken up.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b637e",
   "metadata": {},
   "source": [
    "# Create the Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, you will run the linear regression model on your training data. You could call this linear model\n",
    "# anything you’d like, but below you’ll see it has been named lm. You will then fit this model to the \n",
    "# training data using the .fit() function, specifying the x and y training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5189a7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get this spit back to you, then you know it's worked ok: LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cef011",
   "metadata": {},
   "source": [
    "# Interpreting Supervised Machine Learning Model Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you have created the model, it's time to take a peek at it and determine whether it is any good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fa0bc",
   "metadata": {},
   "source": [
    "# Examine Predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you’ve created your model, you can see the predictions it has made about housing price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ba8854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.77852916,  8.35848599, 23.1113017 , 47.67384657, 30.05251015,\n",
       "       37.468435  , 38.01762284, 41.08294225, 46.50080685, 40.34536509,\n",
       "       43.87818623, 33.77279613, 40.08116941, 37.31066596, 46.15211908,\n",
       "       48.22093568, 39.48594154, 46.43844951, 49.94962395, 47.552992  ,\n",
       "       41.60580876, 52.60152777, 47.16226231, 37.48194878, 32.40811002,\n",
       "       50.67597957, 39.35917038, 47.99287312, 45.4694465 , 39.33112551,\n",
       "       49.61736207, 42.53188577, 42.96261018, 46.15577268, 44.94124757,\n",
       "        7.13730951, 39.15074038, 39.77497805,  7.07979164, 54.43242047,\n",
       "       31.26660065, 46.90435905, 24.89017208, 48.80711134, 42.6710441 ,\n",
       "       50.08982154, 41.0044385 , 37.39701978, 44.86394799, 36.76558821,\n",
       "       46.8133099 , 35.89912014, 42.35933217, 14.7421879 , 38.74428879,\n",
       "       47.50157796, 43.06612319, 45.44985241, 43.77496083, 39.48259244,\n",
       "       34.31225036, 45.52392252, 42.44560897, 42.0625614 , 51.89857656,\n",
       "       42.74806676, 24.28752167, 48.68058491, 31.25018334, 40.06346133,\n",
       "       43.6178354 , 48.68240545, 14.21653961, 35.23519914, 14.76427345,\n",
       "       43.25900943, 33.7425475 , 44.18683365, 42.22275082, 11.21376847,\n",
       "       45.59819933, 36.51146884, 42.35933217, 29.6210743 , 52.1620338 ,\n",
       "       14.75338445, 35.2064402 , 33.2566497 , 40.22496408, 14.09152523,\n",
       "       47.50926438, 34.37096962, 45.11380117, 25.01302325, 33.54177669,\n",
       "       30.06022011, 23.53156264, 46.64460151, 27.77120309, 37.6169996 ,\n",
       "       47.67413156, 30.23443112, 38.67231057, 40.81568301, 48.46849393,\n",
       "       27.3840657 , 28.40540026, 30.66691363, 32.9788148 , 42.56064471,\n",
       "       46.55832471, 46.09825481, 49.45208001, 33.9117351 , 47.53802332,\n",
       "       42.53188577, 42.46357723, 46.50080685, 43.96908151, 44.54806893,\n",
       "       51.11916869, 42.91232964, 32.24698686, 14.78214338, 35.89873172,\n",
       "       33.94049403, 14.38904544, 42.79542479, 49.39456214, 43.94751443,\n",
       "       28.31477818, 39.86164578, 45.17199505, 48.46849393, 52.57276884,\n",
       "       38.23919165, 36.23935025, 45.52392252, 42.3923762 , 39.99498272,\n",
       "       34.53964756, 48.84883348, 32.83255357, 45.68510943, 33.27573801,\n",
       "       39.69163345, 15.22305451, 33.74403719, 39.2721091 , 24.77513635,\n",
       "       46.01197801, 45.95357381, 31.62887841, 31.20555338, 46.55832471,\n",
       "       33.73827309, 46.82193446, 29.9451677 , 46.78249532, 11.76318638,\n",
       "       52.77408137, 46.49381411, 47.21978018, 54.51869727, 40.81742848,\n",
       "       52.86035817])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lm.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This information is not super useful by itself, but plotting it gives you a better idea of how accurate\n",
    "# your predictions (and thus your model) is. The straighter the line, the better the model fit. \n",
    "# Go ahead and make a scatterplot with the plt.scatter() function, graphing the y_test data against the \n",
    "# predictions from your training model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea738f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17fa05160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the accuracy is not wonderful just by eyeballing it, but you can also quantify it a number of different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c1a9d",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5edbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6442380845121868\n"
     ]
    }
   ],
   "source": [
    "# The first way is to print an accuracy score for this model. Place the .score() function inside the\n",
    "# print() function with an argument of your testing data to get it:\n",
    "\n",
    "print(\"Score:\", lm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bed010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means your model is accurate approximately 64% of the time, which is not too shabby in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89feaba3",
   "metadata": {},
   "source": [
    "# Examining Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74104e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next way to determine model fit is to look at the error terms. This is just another way to quantify \n",
    "# the residuals - how close is your predicted data from the real data? There are many different mathematical \n",
    "# ways to examine error, but you will look at mean absolute error (MAE), mean squared error (MSE) and root mean \n",
    "# squared error (RMSE). There are no cut-off values when interpreting error scores, because each model with \n",
    "# different variables and different units for those variables will generate radically different error values. \n",
    "# The main thing to know about interpreting error is that the smaller the error value, the better, and they range \n",
    "# from zero to infinity. You want as close to zero as you can get.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eea6f8",
   "metadata": {},
   "source": [
    "# - Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9a5b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.550201321415231"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is exactly what it sounds like - the average amount of error between the prediction and the real data.\n",
    "# It's a nice one to use because it's pretty simple to understand. To get it, utilize the metrics package from \n",
    "# sklearn and the mean_absolute_error() function:\n",
    "\n",
    "metrics.mean_absolute_error(y_test, predictions)\n",
    "\n",
    "# You'll place as arguments y_test and predictions, because these are the things you are comparing to get error. \n",
    "# Here is the resulting statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the lowest you can have is 0, a value of 5.55 is pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf849c3",
   "metadata": {},
   "source": [
    "# - Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7e7789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.37572854491987"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the square of the absolute error from above. It's a good one to use because it takes into account\n",
    "# large amounts of error, which often happens in the real world. You'll get it with the mean_squared_error() \n",
    "# function from the sklearn metrics package:\n",
    "\n",
    "metrics.mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that because it is squared, it comes out much larger than the mean absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbae599",
   "metadata": {},
   "source": [
    "# - Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0a6408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.373990001682934"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one is the square root of the mean squared error you saw above. It is probably the most popular.\n",
    "# You will need to utilize the numpy sqrt() function to get the square root of the mean_squared_error() \n",
    "# function you used above:\n",
    "\n",
    "np.sqrt(metrics.mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, this model fits decently well - 7 is pretty close to zero! That is not to say that there aren't better\n",
    "# fitting models for this data out there - there very well might be! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e8af38",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1dd5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# You will need from sklearn.model_selection the packages for KFold and for cross_val_score.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc94e4",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea83ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will use the same data as above - realestate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd085f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal\n",
    "# With the above data, your goal is to accurately predict housing prices. \n",
    "# To ensure this is the most accurate and rigorous model, you will be cross-validating it using the k-folds method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7769b9",
   "metadata": {},
   "source": [
    "# Create the Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b00a407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [  0   1   2   3   7   8   9  10  14  15  16  19  20  21  22  24  25  26\n",
      "  28  30  31  32  33  34  35  36  37  38  42  43  44  45  46  47  48  49\n",
      "  50  51  52  53  54  55  56  57  60  63  64  66  68  70  71  72  74  75\n",
      "  76  77  79  83  84  86  87  88  94  96  97  99 100 103 104 105 108 109\n",
      " 110 111 112 113 114 115 116 118 121 123 124 126 128 129 130 131 133 134\n",
      " 135 136 137 138 140 141 142 143 144 145 147 148 149 150 151 152 153 154\n",
      " 155 156 157 158 160 163 166 167 168 169 170 174 175 176 177 178 181 182\n",
      " 183 184 188 190 193 194 195 196 197 198 199 200 201 202 203 205 206 208\n",
      " 209 210 212 215 216 217 219 220 221 222 224 225 226 227 229 231 234 235\n",
      " 236 237 239 240 241 243 246 248 249 250 251 252 253 254 255 258 259 260\n",
      " 262 263 264 265 266 267 269 275 276 277 278 279 280 281 282 283 284 285\n",
      " 287 288 290 293 296 297 301 302 303 305 306 307 308 309 310 313 315 316\n",
      " 317 318 319 321 324 326 327 328 331 333 334 335 336 339 340 342 343 344\n",
      " 345 347 349 352 353 354 355 356 357 358 359 361 362 365 366 369 371 372\n",
      " 375 376 377 381 382 383 384 386 387 390 391 392 393 394 396 399 400 402\n",
      " 404 406 407 408 411 413], test: [  4   5   6  11  12  13  17  18  23  27  29  39  40  41  58  59  61  62\n",
      "  65  67  69  73  78  80  81  82  85  89  90  91  92  93  95  98 101 102\n",
      " 106 107 117 119 120 122 125 127 132 139 146 159 161 162 164 165 171 172\n",
      " 173 179 180 185 186 187 189 191 192 204 207 211 213 214 218 223 228 230\n",
      " 232 233 238 242 244 245 247 256 257 261 268 270 271 272 273 274 286 289\n",
      " 291 292 294 295 298 299 300 304 311 312 314 320 322 323 325 329 330 332\n",
      " 337 338 341 346 348 350 351 360 363 364 367 368 370 373 374 378 379 380\n",
      " 385 388 389 395 397 398 401 403 405 409 410 412]\n",
      "train: [  1   2   3   4   5   6   7  10  11  12  13  15  17  18  20  22  23  25\n",
      "  26  27  29  30  36  37  39  40  41  43  49  50  52  54  57  58  59  60\n",
      "  61  62  64  65  67  68  69  71  72  73  74  75  76  77  78  80  81  82\n",
      "  83  85  86  87  89  90  91  92  93  94  95  96  97  98 101 102 103 104\n",
      " 106 107 109 114 115 117 118 119 120 121 122 125 126 127 129 130 132 133\n",
      " 136 139 140 141 143 144 146 148 149 151 152 153 155 156 159 161 162 164\n",
      " 165 166 170 171 172 173 176 178 179 180 181 182 183 185 186 187 189 190\n",
      " 191 192 193 194 195 196 198 200 202 203 204 207 209 210 211 213 214 215\n",
      " 216 218 220 223 226 228 230 232 233 235 237 238 239 240 241 242 243 244\n",
      " 245 247 252 253 254 255 256 257 259 261 262 263 264 265 266 268 269 270\n",
      " 271 272 273 274 276 278 279 280 281 282 286 288 289 291 292 294 295 297\n",
      " 298 299 300 301 302 303 304 308 309 311 312 313 314 316 317 318 319 320\n",
      " 321 322 323 325 329 330 332 335 336 337 338 339 340 341 345 346 347 348\n",
      " 350 351 352 357 359 360 363 364 365 366 367 368 369 370 372 373 374 376\n",
      " 378 379 380 381 382 385 386 388 389 390 393 395 396 397 398 399 401 402\n",
      " 403 405 407 409 410 412], test: [  0   8   9  14  16  19  21  24  28  31  32  33  34  35  38  42  44  45\n",
      "  46  47  48  51  53  55  56  63  66  70  79  84  88  99 100 105 108 110\n",
      " 111 112 113 116 123 124 128 131 134 135 137 138 142 145 147 150 154 157\n",
      " 158 160 163 167 168 169 174 175 177 184 188 197 199 201 205 206 208 212\n",
      " 217 219 221 222 224 225 227 229 231 234 236 246 248 249 250 251 258 260\n",
      " 267 275 277 283 284 285 287 290 293 296 305 306 307 310 315 324 326 327\n",
      " 328 331 333 334 342 343 344 349 353 354 355 356 358 361 362 371 375 377\n",
      " 383 384 387 391 392 394 400 404 406 408 411 413]\n",
      "train: [  0   4   5   6   8   9  11  12  13  14  16  17  18  19  21  23  24  27\n",
      "  28  29  31  32  33  34  35  38  39  40  41  42  44  45  46  47  48  51\n",
      "  53  55  56  58  59  61  62  63  65  66  67  69  70  73  78  79  80  81\n",
      "  82  84  85  88  89  90  91  92  93  95  98  99 100 101 102 105 106 107\n",
      " 108 110 111 112 113 116 117 119 120 122 123 124 125 127 128 131 132 134\n",
      " 135 137 138 139 142 145 146 147 150 154 157 158 159 160 161 162 163 164\n",
      " 165 167 168 169 171 172 173 174 175 177 179 180 184 185 186 187 188 189\n",
      " 191 192 197 199 201 204 205 206 207 208 211 212 213 214 217 218 219 221\n",
      " 222 223 224 225 227 228 229 230 231 232 233 234 236 238 242 244 245 246\n",
      " 247 248 249 250 251 256 257 258 260 261 267 268 270 271 272 273 274 275\n",
      " 277 283 284 285 286 287 289 290 291 292 293 294 295 296 298 299 300 304\n",
      " 305 306 307 310 311 312 314 315 320 322 323 324 325 326 327 328 329 330\n",
      " 331 332 333 334 337 338 341 342 343 344 346 348 349 350 351 353 354 355\n",
      " 356 358 360 361 362 363 364 367 368 370 371 373 374 375 377 378 379 380\n",
      " 383 384 385 387 388 389 391 392 394 395 397 398 400 401 403 404 405 406\n",
      " 408 409 410 411 412 413], test: [  1   2   3   7  10  15  20  22  25  26  30  36  37  43  49  50  52  54\n",
      "  57  60  64  68  71  72  74  75  76  77  83  86  87  94  96  97 103 104\n",
      " 109 114 115 118 121 126 129 130 133 136 140 141 143 144 148 149 151 152\n",
      " 153 155 156 166 170 176 178 181 182 183 190 193 194 195 196 198 200 202\n",
      " 203 209 210 215 216 220 226 235 237 239 240 241 243 252 253 254 255 259\n",
      " 262 263 264 265 266 269 276 278 279 280 281 282 288 297 301 302 303 308\n",
      " 309 313 316 317 318 319 321 335 336 339 340 345 347 352 357 359 365 366\n",
      " 369 372 376 381 382 386 390 393 396 399 402 407]\n"
     ]
    }
   ],
   "source": [
    "# You will use the KFold() function to create your different training and test sets.\n",
    "# By inputting the 3, you have chosen to have 3 iterations, a good number given the small number of cases in your\n",
    "# dataset. Then the argument True means that you want your data to be shuffled. Lastly, if you choose to \n",
    "# shuffle your data, then you can specify the randomization version - just like with train_test_split().\n",
    "# If you were doing this on your own, it wouldn't matter, but since you are following along, and you want your\n",
    "# numbers to be the same, specify the 1 as done here so that everyone ends up with the same randomization.\n",
    "\n",
    "kfold = KFold(n_splits = 3, shuffle=True, random_state=1)\n",
    "for train, test in kfold.split(x,y):\n",
    "    print('train: %s, test: %s' % (train,test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de130eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62051774 0.50393467 0.55970703]\n"
     ]
    }
   ],
   "source": [
    "# The ability to run something cross-validated is already built into sklearn.\n",
    "# If you were to do this the long way, you would use these printed index lists and drop rows from your \n",
    "# column to make six separate data sets, 3 for training and three for testing, and then use the above model \n",
    "# code to test each set of train and test data and then average together. Sounds long and time consuming, right? \n",
    "# Well, luckily it’s as simple as one line of code with sklearn:\n",
    "\n",
    "print(cross_val_score(lm, x,y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You’ll notice that these scores vary somewhat. That is to be expected. Looks like the first trained model was \n",
    "# accurate 62% of the time, while the second model was accurate 50% of the time and the third model was accurate \n",
    "# 56% of the time.\n",
    "\n",
    "# Using cross-validation, your model has now been thoroughly tested, and you should feel secure in your knowledge\n",
    "# that you have created a rigorous model that has stood up to some serious testing! You also have a better idea of \n",
    "# how the accuracy might vary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python399jvsc74a57bd050292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
